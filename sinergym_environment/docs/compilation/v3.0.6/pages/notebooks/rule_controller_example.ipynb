{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Rule Controller example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "First, we import all the used libraries, remember to always import `sinergym` even if it says is not used, because that is needed to define the environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from typing import List, Any, Sequence\n",
    "from sinergym.utils.common import get_season_comfort_range\n",
    "from sinergym.utils.constants import YEAR\n",
    "from datetime import datetime\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import sinergym"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, we can define the environment we want to use, in our case we are using the Eplus demo.\n",
    "Don't forget to deactivate the `flag_normalization`. It is important due to the fact that *MyRuleBasedController*\n",
    "works with real values, not `[-1,1]` space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#==============================================================================================#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Creating Gymnasium environment... [5zone-hot-continuous-v1]\u001b[0m\n",
      "#==============================================================================================#\n",
      "\u001b[38;20m[MODELING] (INFO) : Experiment working directory created [/workspaces/sinergym/examples/Eplus-env-5zone-hot-continuous-v1-res2]\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : runperiod established: {'start_day': 1, 'start_month': 1, 'start_year': 1991, 'end_day': 31, 'end_month': 12, 'end_year': 1991, 'start_weekday': 1, 'n_steps_per_hour': 4}\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Episode length (seconds): 31536000.0\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : timestep size (seconds): 900.0\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : timesteps per episode: 35040\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Model Config is correct.\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment 5zone-hot-continuous-v1 created successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Eplus-5zone-hot-continuous-v1', flag_normalization=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "For the Rule-base controller have a look at the already defined controllers, there is one for each building, since the demo is based on the 5Zone building we are extending that controller and defining the action function we desire, feel free to play with the function to define your own action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sinergym.utils.controllers import RBC5Zone\n",
    "\n",
    "class MyRuleBasedController(RBC5Zone):\n",
    "\n",
    "    def act(self, observation: List[Any]) -> Sequence[Any]:\n",
    "        \"\"\"Select action based on outdoor air drybulb temperature and daytime.\n",
    "\n",
    "        Args:\n",
    "            observation (List[Any]): Perceived observation.\n",
    "\n",
    "        Returns:\n",
    "            Sequence[Any]: Action chosen.\n",
    "        \"\"\"\n",
    "        obs_dict = dict(zip(self.env.get_wrapper_attr('observation_variables'), observation))\n",
    "\n",
    "        out_temp = obs_dict['outdoor_temperature']\n",
    "\n",
    "        day = int(obs_dict['day_of_month'])\n",
    "        month = int(obs_dict['month'])\n",
    "        hour = int(obs_dict['hour'])\n",
    "        year = int(obs_dict['year'] if obs_dict.get('year',False) else YEAR)\n",
    "\n",
    "        summer_start_date = datetime(year, 6, 1)\n",
    "        summer_final_date = datetime(year, 9, 30)\n",
    "\n",
    "        current_dt = datetime(year, month, day)\n",
    "\n",
    "        # Get season comfort range\n",
    "        if current_dt >= summer_start_date and current_dt <= summer_final_date:\n",
    "            season_comfort_range = self.setpoints_summer\n",
    "        else:\n",
    "            season_comfort_range = self.setpoints_summer\n",
    "        season_comfort_range = get_season_comfort_range(1991,month, day)\n",
    "        # Update setpoints\n",
    "        in_temp = obs_dict['air_temperature']\n",
    "\n",
    "        current_heat_setpoint = obs_dict[\n",
    "            'htg_setpoint']\n",
    "        current_cool_setpoint = obs_dict[\n",
    "            'clg_setpoint']\n",
    "\n",
    "        new_heat_setpoint = current_heat_setpoint\n",
    "        new_cool_setpoint = current_cool_setpoint\n",
    "\n",
    "        if in_temp < season_comfort_range[0]:\n",
    "            new_heat_setpoint = current_heat_setpoint + 1\n",
    "            new_cool_setpoint = current_cool_setpoint + 1\n",
    "        elif in_temp > season_comfort_range[1]:\n",
    "            new_cool_setpoint = current_cool_setpoint - 1\n",
    "            new_heat_setpoint = current_heat_setpoint - 1\n",
    "\n",
    "        #Clip setpoints to the action space\n",
    "        if new_heat_setpoint>self.env.get_wrapper_attr('action_space').high[0]:\n",
    "            new_heat_setpoint=self.env.get_wrapper_attr('action_space').high[0]\n",
    "        if new_heat_setpoint<self.env.get_wrapper_attr('action_space').low[0]:\n",
    "            new_heat_setpoint=self.env.get_wrapper_attr('action_space').low[0]\n",
    "        if new_cool_setpoint>self.env.get_wrapper_attr('action_space').high[1]:\n",
    "            new_cool_setpoint=self.env.get_wrapper_attr('action_space').high[1]\n",
    "        if new_cool_setpoint<self.env.get_wrapper_attr('action_space').low[1]:\n",
    "            new_cool_setpoint=self.env.get_wrapper_attr('action_space').low[1]\n",
    "\n",
    "        action = (new_heat_setpoint, new_cool_setpoint)\n",
    "        if current_dt.weekday() > 5 or hour in range(22, 6):\n",
    "            #weekend or night\n",
    "            action = (18.33, 23.33)\n",
    "\n",
    "        return action"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now that we have our controller ready, we can use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Starting a new episode... [5zone-hot-continuous-v1] [Episode 1]\u001b[0m\n",
      "#----------------------------------------------------------------------------------------------#\n",
      "\u001b[38;20m[MODELING] (INFO) : Episode directory created [/workspaces/sinergym/examples/Eplus-env-5zone-hot-continuous-v1-res2/Eplus-env-sub_run1]\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Weather file USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw used.\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Updated building model with whole Output:Variable available names\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Updated building model with whole Output:Meter available names\u001b[0m\n",
      "\u001b[38;20m[MODELING] (INFO) : Adapting weather to building model. [USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw]\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Saving episode output path... [/workspaces/sinergym/examples/Eplus-env-5zone-hot-continuous-v1-res2/Eplus-env-sub_run1/output]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/opyplus/weather_data/weather_data.py:493: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  epw_content = self._headers_to_epw(use_datetimes=use_datetimes) + df.to_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m[SIMULATOR] (INFO) : Running EnergyPlus with args: ['-w', '/workspaces/sinergym/examples/Eplus-env-5zone-hot-continuous-v1-res2/Eplus-env-sub_run1/USA_AZ_Davis-Monthan.AFB.722745_TMY3.epw', '-d', '/workspaces/sinergym/examples/Eplus-env-5zone-hot-continuous-v1-res2/Eplus-env-sub_run1/output', '/workspaces/sinergym/examples/Eplus-env-5zone-hot-continuous-v1-res2/Eplus-env-sub_run1/5ZoneAutoDXVAV.epJSON']\u001b[0m\n",
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Episode 1 started.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers initialized.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : handlers are ready.\u001b[0m\n",
      "\u001b[38;20m[SIMULATOR] (INFO) : System is ready.\u001b[0m\n",
      "Reward:  -1.483546380748924 {'time_elapsed(hours)': 0.5, 'month': 1, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (15.0, 30.0), 'timestep': 2, 'reward': -1.483546380748924, 'energy_term': -0.05542625239599594, 'comfort_term': -1.4281201283529281, 'reward_weight': 0.5, 'abs_energy': 1108.5250479199187, 'abs_comfort': 2.8562402567058562, 'energy_values': [1108.5250479199187], 'temp_values': [17.143759743294144]}\n",
      "Progress: |*--------------------------------------------------------------------------------------------------| 1%\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/gymnasium/spaces/box.py:240: UserWarning: \u001b[33mWARN: Casting input x to numpy array.\u001b[0m\n",
      "  gym.logger.warn(\"Casting input x to numpy array.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward:  -4201.891175579272 {'time_elapsed(hours)': 744.375, 'month': 2, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (15.0, 22.5), 'timestep': 2977, 'reward': -0.029685366369608755, 'energy_term': -0.005629685362144396, 'comfort_term': -0.024055681007464358, 'reward_weight': 0.5, 'abs_energy': 112.5937072428879, 'abs_comfort': 0.048111362014928716, 'energy_values': [112.5937072428879], 'temp_values': [19.95188863798507]}\n",
      "Reward:  -5250.541987103698 {'time_elapsed(hours)': 1416.25, 'month': 3, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (19.0, 26.5), 'timestep': 5665, 'reward': -0.6145943008400387, 'energy_term': -0.008821406521840552, 'comfort_term': -0.6057728943181981, 'reward_weight': 0.5, 'abs_energy': 176.42813043681105, 'abs_comfort': 1.2115457886363963, 'energy_values': [176.42813043681105], 'temp_values': [18.788454211363604]}\n",
      "Reward:  -8271.145974472573 {'time_elapsed(hours)': 2160.25, 'month': 4, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (18.33, 23.33), 'timestep': 8641, 'reward': -0.0, 'energy_term': -0.0, 'comfort_term': -0.0, 'reward_weight': 0.5, 'abs_energy': 0.0, 'abs_comfort': 0.0, 'energy_values': [0.0], 'temp_values': [20.857805333622345]}\n",
      "Reward:  -11552.686587143759 {'time_elapsed(hours)': 2880.25, 'month': 5, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (15.0, 22.5), 'timestep': 11521, 'reward': -0.16617330266530494, 'energy_term': -0.0, 'comfort_term': -0.16617330266530494, 'reward_weight': 0.5, 'abs_energy': 0.0, 'abs_comfort': 0.3323466053306099, 'energy_values': [0.0], 'temp_values': [23.83234660533061]}\n",
      "Reward:  -15420.699633619523 {'time_elapsed(hours)': 3624.25, 'month': 6, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (15.0, 22.5), 'timestep': 14497, 'reward': -0.028967677878133813, 'energy_term': -0.0, 'comfort_term': -0.028967677878133813, 'reward_weight': 0.5, 'abs_energy': 0.0, 'abs_comfort': 0.057935355756267626, 'energy_values': [0.0], 'temp_values': [26.057935355756268]}\n",
      "Reward:  -18942.570751340998 {'time_elapsed(hours)': 4344.375, 'month': 7, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (18.33, 23.33), 'timestep': 17377, 'reward': -1.1033173838869228, 'energy_term': -0.0, 'comfort_term': -1.1033173838869228, 'reward_weight': 0.5, 'abs_energy': 0.0, 'abs_comfort': 2.2066347677738456, 'energy_values': [0.0], 'temp_values': [28.206634767773846]}\n",
      "Reward:  -21604.94705187841 {'time_elapsed(hours)': 5088.25, 'month': 8, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (15.0, 22.5), 'timestep': 20353, 'reward': -0.4214044541910553, 'energy_term': -0.0, 'comfort_term': -0.4214044541910553, 'reward_weight': 0.5, 'abs_energy': 0.0, 'abs_comfort': 0.8428089083821106, 'energy_values': [0.0], 'temp_values': [26.84280890838211]}\n",
      "Reward:  -24271.796197931737 {'time_elapsed(hours)': 5832.25, 'month': 9, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (15.0, 22.5), 'timestep': 23329, 'reward': -0.0, 'energy_term': -0.0, 'comfort_term': -0.0, 'reward_weight': 0.5, 'abs_energy': 0.0, 'abs_comfort': 0.0, 'energy_values': [0.0], 'temp_values': [25.86941925543133]}\n",
      "Reward:  -26560.850150407623 {'time_elapsed(hours)': 6552.3125, 'month': 10, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (15.0, 22.5), 'timestep': 26209, 'reward': -1.1548898253501159, 'energy_term': -0.06446283743025183, 'comfort_term': -1.090426987919864, 'reward_weight': 0.5, 'abs_energy': 1289.2567486050366, 'abs_comfort': 2.180853975839728, 'energy_values': [1289.2567486050366], 'temp_values': [25.680853975839728]}\n",
      "Reward:  -33523.36171890597 {'time_elapsed(hours)': 7296.25, 'month': 11, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (15.0, 22.5), 'timestep': 29185, 'reward': -0.004536449977537947, 'energy_term': -0.004536449977537947, 'comfort_term': -0.0, 'reward_weight': 0.5, 'abs_energy': 90.72899955075894, 'abs_comfort': 0.0, 'energy_values': [90.72899955075894], 'temp_values': [21.21277283853061]}\n",
      "Reward:  -37023.11595864533 {'time_elapsed(hours)': 8016.25, 'month': 12, 'day': 1, 'hour': 0, 'is_raining': False, 'action': (18.0, 25.5), 'timestep': 32065, 'reward': -0.3202558614716244, 'energy_term': -0.004536449977537947, 'comfort_term': -0.31571941149408644, 'reward_weight': 0.5, 'abs_energy': 90.72899955075894, 'abs_comfort': 0.6314388229881729, 'energy_values': [90.72899955075894], 'temp_values': [19.368561177011827]}\n",
      "Progress: |***************************************************************************************************| 99%\n",
      "Episode  0 Mean reward:  -1.1397504554157643 Cumulative reward:  -39936.855957765714\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# create rule-based controller\n",
    "agent = MyRuleBasedController(env)\n",
    "\n",
    "for i in range(1):\n",
    "    obs, info = env.reset()\n",
    "    rewards = []\n",
    "    terminated = False\n",
    "    current_month = 0\n",
    "while not terminated:\n",
    "    action = agent.act(obs)\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    rewards.append(reward)\n",
    "    if info['month'] != current_month:  # display results every month\n",
    "        current_month = info['month']\n",
    "        print('Reward: ', sum(rewards), info)\n",
    "print(\n",
    "    'Episode ',\n",
    "    i,\n",
    "    'Mean reward: ',\n",
    "    np.mean(rewards),\n",
    "    'Cumulative reward: ',\n",
    "    sum(rewards))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Always remember to close the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;20m[ENVIRONMENT] (INFO) : Environment closed. [5zone-hot-continuous-v1]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".. note:: For more information about our defines controllers and how create a new one, please, visit our [Controller Documentation](https://ugr-sail.github.io/sinergym/compilation/html/pages/controllers.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
