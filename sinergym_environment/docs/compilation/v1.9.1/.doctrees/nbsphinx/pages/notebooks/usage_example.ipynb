{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Basic example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Sinergym uses the standard OpenAI gym API. Lets see how to create a basic loop.\n",
    "\n",
    "First we need to include sinergym and create an environment, in our case using 'Eplus-demo-v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 13:45:00,690] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Updating idf Site:Location and SizingPeriod:DesignDay(s) to weather and ddy file...\n",
      "[2022-05-16 13:45:00,692] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Setting up extra configuration in building model if exists...\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import sinergym\n",
    "env = gym.make('Eplus-demo-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "At first glance may appear that sinergym is only imported but never used, but by importing Sinergym all its :ref:`Environments`\n",
    "are defined to be used, in this case 'Eplus-demo-v1' with all the information contained in the idf file and the config file.\n",
    "\n",
    "After this simple definition we are ready to loop the episodes, for this simple example we are going to consider only 1 episode. In summary the code we need is something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 13:45:00,750] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
      "[2022-05-16 13:45:00,764] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-demo-v1-res4/Eplus-env-sub_run1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward:  -0.2841864127941599 {'timestep': 1, 'time_elapsed': 900, 'year': 1991, 'month': 1, 'day': 1, 'hour': 0, 'total_power': 5683.728255883198, 'total_power_no_units': -0.5683728255883198, 'comfort_penalty': -0.0, 'temperatures': [20.09252236706715], 'out_temperature': 1.8, 'action_': [20.0, 25.0]}\n",
      "Reward:  -1901.9936487214263 {'timestep': 2976, 'time_elapsed': 2678400, 'year': 1991, 'month': 2, 'day': 1, 'hour': 0, 'total_power': 5114.533558613195, 'total_power_no_units': -0.5114533558613196, 'comfort_penalty': -2.4418498744559507, 'temperatures': [17.55815012554405], 'out_temperature': -7.0, 'action_': [17.0, 28.0]}\n",
      "Reward:  -3644.0794939860984 {'timestep': 5664, 'time_elapsed': 5097600, 'year': 1991, 'month': 3, 'day': 1, 'hour': 0, 'total_power': 904.3033400850004, 'total_power_no_units': -0.09043033400850005, 'comfort_penalty': -1.0265696607017887, 'temperatures': [18.97343033929821], 'out_temperature': 8.1, 'action_': [18.0, 27.0]}\n",
      "Reward:  -4748.919758737626 {'timestep': 8640, 'time_elapsed': 7776000, 'year': 1991, 'month': 4, 'day': 1, 'hour': 0, 'total_power': 186.5934720667916, 'total_power_no_units': -0.018659347206679163, 'comfort_penalty': -0.0, 'temperatures': [20.0754550796285], 'out_temperature': 7.7, 'action_': [19.0, 26.0]}\n",
      "Reward:  -5551.1305170053665 {'timestep': 11520, 'time_elapsed': 10368000, 'year': 1991, 'month': 5, 'day': 1, 'hour': 0, 'total_power': 186.5934720667916, 'total_power_no_units': -0.018659347206679163, 'comfort_penalty': -0.0, 'temperatures': [20.18156576151877], 'out_temperature': 13.0, 'action_': [18.0, 27.0]}\n",
      "Reward:  -6287.013473001529 {'timestep': 14496, 'time_elapsed': 13046400, 'year': 1991, 'month': 6, 'day': 1, 'hour': 0, 'total_power': 311.2037327096765, 'total_power_no_units': -0.03112037327096765, 'comfort_penalty': -1.9682857678869006, 'temperatures': [21.0317142321131], 'out_temperature': 18.4, 'action_': [19.0, 26.0]}\n",
      "Reward:  -9315.732274431955 {'timestep': 17376, 'time_elapsed': 15638400, 'year': 1991, 'month': 7, 'day': 1, 'hour': 0, 'total_power': 215.8105427085715, 'total_power_no_units': -0.02158105427085715, 'comfort_penalty': -2.7372908133191203, 'temperatures': [20.26270918668088], 'out_temperature': 17.7, 'action_': [16.0, 29.0]}\n",
      "Reward:  -12605.000758314483 {'timestep': 20352, 'time_elapsed': 18316800, 'year': 1991, 'month': 8, 'day': 1, 'hour': 0, 'total_power': 7396.796157794615, 'total_power_no_units': -0.7396796157794616, 'comfort_penalty': -2.15506148558136, 'temperatures': [20.84493851441864], 'out_temperature': 20.6, 'action_': [21.0, 21.0]}\n",
      "Reward:  -15937.079728458055 {'timestep': 23328, 'time_elapsed': 20995200, 'year': 1991, 'month': 9, 'day': 1, 'hour': 0, 'total_power': 1175.521212911868, 'total_power_no_units': -0.11755212129118679, 'comfort_penalty': -2.0021315671471918, 'temperatures': [20.99786843285281], 'out_temperature': 18.8, 'action_': [21.0, 21.0]}\n",
      "Reward:  -18793.23508185701 {'timestep': 26208, 'time_elapsed': 23587200, 'year': 1991, 'month': 10, 'day': 1, 'hour': 0, 'total_power': 2782.859159891797, 'total_power_no_units': -0.27828591598917973, 'comfort_penalty': -0.0, 'temperatures': [21.97042552719191], 'out_temperature': 13.3, 'action_': [22.0, 23.0]}\n",
      "Reward:  -19698.456143954274 {'timestep': 29184, 'time_elapsed': 26265600, 'year': 1991, 'month': 11, 'day': 1, 'hour': 0, 'total_power': 186.5934720667916, 'total_power_no_units': -0.018659347206679163, 'comfort_penalty': -0.22708878036418056, 'temperatures': [19.77291121963582], 'out_temperature': 13.0, 'action_': [18.0, 27.0]}\n",
      "Reward:  -20747.431528649675 {'timestep': 32064, 'time_elapsed': 28857600, 'year': 1991, 'month': 12, 'day': 1, 'hour': 0, 'total_power': 6130.917053865358, 'total_power_no_units': -0.6130917053865358, 'comfort_penalty': -0.0, 'temperatures': [21.33530558238196], 'out_temperature': 5.1, 'action_': [22.0, 23.0]}\n",
      "Reward:  -22511.33303888805 {'timestep': 35040, 'time_elapsed': 31536000, 'year': 1992, 'month': 1, 'day': 1, 'hour': 0, 'total_power': 12885.27471315695, 'total_power_no_units': -1.2885274713156951, 'comfort_penalty': -0.0, 'temperatures': [20.22337018610072], 'out_temperature': -12.0, 'action_': [22.0, 23.0]}\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    obs = env.reset()\n",
    "    rewards = []\n",
    "    done = False\n",
    "    current_month = 0\n",
    "    while not done:\n",
    "        a = env.action_space.sample()\n",
    "        obs, reward, done, info = env.step(a)\n",
    "        rewards.append(reward)\n",
    "        if info['month'] != current_month:  # display results every month\n",
    "            current_month = info['month']\n",
    "            print('Reward: ', sum(rewards), info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And as always don't forget to close the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-05-16 13:45:15,857] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus simulation closed successfully. \n"
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we can see the final rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward:  -0.642446719146322 Cumulative reward:  -22511.33303888805\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'Mean reward: ',\n",
    "    np.mean(rewards),\n",
    "    'Cumulative reward: ',\n",
    "    sum(rewards))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
