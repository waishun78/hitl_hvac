{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# DRL usage example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We are going to rely on the script available in the repository root called `DRL_battery.py`. This script applies all the possibilities that Sinergym has to work with deep reinforcement learning algorithms and set parameters to everything so that we can define the training options from the execution of the script.\n",
    "\n",
    ".. note:: For more information about how run `DRL_battery.py`, please, see [DRL documentation](https://ugr-sail.github.io/sinergym/compilation/html/pages/deep-reinforcement-learning.html#how-use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "import sinergym\n",
    "from sinergym.utils.callbacks import LoggerEvalCallback\n",
    "from sinergym.utils.rewards import *\n",
    "from sinergym.utils.wrappers import LoggerWrapper\n",
    "from datetime import datetime\n",
    "import gym\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.callbacks import CallbackList\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "First let's define some strings and variables for the execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "environment = \"Eplus-demo-v1\"\n",
    "episodes = 4\n",
    "experiment_date = datetime.today().strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "# register run name\n",
    "name = F\"DQN-{environment}-episodes_{episodes}({experiment_date})\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now we are ready to create the Gym Environment. Here we use the run name defined before as well as the type of reward, in our case we are going to use the LinearReward defined by `Sinergym`. You can define your own or use any of the other defined by `Sinergym` have a look at ref:`rewards` for more information on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-10-07 09:01:59,433] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Updating idf ExternalInterface object if it is not present...\n",
      "[2022-10-07 09:01:59,434] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Updating idf Site:Location and SizingPeriod:DesignDay(s) to weather and ddy file...\n",
      "[2022-10-07 09:01:59,436] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Updating idf OutPut:Variable and variables XML tree model for BVCTB connection.\n",
      "[2022-10-07 09:01:59,437] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Setting up extra configuration in building model if exists...\n",
      "[2022-10-07 09:01:59,437] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Setting up action definition in building model if exists...\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(environment, reward=LinearReward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We can add also a Wrapper to the environment, we are going to use a Logger (extension of ``gym.Wrapper``) this is used to monitor and log the interactions with the environment and save the data into a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env = LoggerWrapper(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "At this point we have the environment all set up and ready to be used to define and create our learning model in this case it's going to be a DQN, but we can use any other (have a look at the `DRL_battery.py` and read :ref:`Deep Reinforcement Learning Integration` for more detailed information on available DRL algorithms).\n",
    "Please feel free to play and change the values of the attributes of our model (or even the model) to see the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = DQN('MlpPolicy', env, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now we need to calculate the number of timesteps of each episode for the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_timesteps_episode = env.simulator._eplus_one_epi_len / \\\n",
    "                      env.simulator._eplus_run_stepsize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now we need to create a vectorized wrapper for the environment because the callbacks we are going to use require a vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "env_vec = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We are going to use the LoggerEval callback to print and save the best model evaluated during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "callbacks = []\n",
    "\n",
    "# Set up Evaluation and saving best model\n",
    "eval_callback = LoggerEvalCallback(\n",
    "    env_vec,\n",
    "    best_model_save_path='best_model/' + name + '/',\n",
    "    log_path='best_model/' + name + '/',\n",
    "    eval_freq=n_timesteps_episode * 2,\n",
    "    deterministic=True,\n",
    "    render=False,\n",
    "    n_eval_episodes=2)\n",
    "callbacks.append(eval_callback)\n",
    "\n",
    "callback = CallbackList(callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This is the number of total time steps for the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "timesteps = episodes * n_timesteps_episode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now is time to train the model with the callbacks defined earlier. This may take a few minutes, depending on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-10-07 09:02:00,041] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
      "[2022-10-07 09:02:00,048] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-demo-v1-res3/Eplus-env-sub_run1\n",
      "[2022-10-07 09:02:13,898] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
      "[2022-10-07 09:02:13,899] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
      "[2022-10-07 09:02:13,906] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-demo-v1-res3/Eplus-env-sub_run2\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 3.5e+04   |\n",
      "|    ep_rew_mean      | -2.36e+04 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 1         |\n",
      "|    fps              | 2443      |\n",
      "|    time_elapsed     | 14        |\n",
      "|    total_timesteps  | 35040     |\n",
      "-----------------------------------\n",
      "[2022-10-07 09:02:36,664] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
      "[2022-10-07 09:02:36,666] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
      "[2022-10-07 09:02:36,683] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-demo-v1-res3/Eplus-env-sub_run3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:265: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:223: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean, casting='unsafe',\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:257: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-10-07 09:02:41,606] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
      "[2022-10-07 09:02:41,608] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
      "[2022-10-07 09:02:41,626] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-demo-v1-res3/Eplus-env-sub_run4\n",
      "[2022-10-07 09:02:56,567] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
      "[2022-10-07 09:02:56,570] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
      "[2022-10-07 09:02:56,585] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-demo-v1-res3/Eplus-env-sub_run5\n",
      "[2022-10-07 09:03:11,570] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
      "[2022-10-07 09:03:11,572] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
      "[2022-10-07 09:03:11,594] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-demo-v1-res3/Eplus-env-sub_run6\n",
      "Eval num_timesteps=70080, episode_reward=-22754.40 +/- 0.00\n",
      "Episode length: 35040.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                     |           |\n",
      "|    comfort_penalty        | -1.48e+04 |\n",
      "|    comfort_violation(%)   | 32.8      |\n",
      "|    mean_ep_length         | 3.5e+04   |\n",
      "|    mean_power_consumption | 3.07e+08  |\n",
      "|    mean_rewards           | -22754.4  |\n",
      "|    power_penalty          | -3.07e+04 |\n",
      "|    std_rewards            | 0.0       |\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 3.5e+04   |\n",
      "|    ep_rew_mean            | -2.33e+04 |\n",
      "|    exploration_rate       | 0.05      |\n",
      "| time/                     |           |\n",
      "|    episodes               | 2         |\n",
      "|    fps                    | 972       |\n",
      "|    time_elapsed           | 72        |\n",
      "|    total_timesteps        | 70080     |\n",
      "| train/                    |           |\n",
      "|    learning_rate          | 0.0001    |\n",
      "|    loss                   | 26.2      |\n",
      "|    n_updates              | 5019      |\n",
      "-----------------------------------------\n",
      "[2022-10-07 09:03:42,104] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
      "[2022-10-07 09:03:42,106] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
      "[2022-10-07 09:03:42,122] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-demo-v1-res3/Eplus-env-sub_run7\n",
      "-----------------------------------\n",
      "| rollout/            |           |\n",
      "|    ep_len_mean      | 3.5e+04   |\n",
      "|    ep_rew_mean      | -2.32e+04 |\n",
      "|    exploration_rate | 0.05      |\n",
      "| time/               |           |\n",
      "|    episodes         | 3         |\n",
      "|    fps              | 1024      |\n",
      "|    time_elapsed     | 102       |\n",
      "|    total_timesteps  | 105120    |\n",
      "| train/              |           |\n",
      "|    learning_rate    | 0.0001    |\n",
      "|    loss             | 15.6      |\n",
      "|    n_updates        | 13779     |\n",
      "-----------------------------------\n",
      "[2022-10-07 09:04:13,329] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
      "[2022-10-07 09:04:13,330] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
      "[2022-10-07 09:04:13,337] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-demo-v1-res3/Eplus-env-sub_run8\n",
      "[2022-10-07 09:04:18,347] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
      "[2022-10-07 09:04:18,349] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
      "[2022-10-07 09:04:18,369] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-demo-v1-res3/Eplus-env-sub_run9\n",
      "[2022-10-07 09:04:34,095] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
      "[2022-10-07 09:04:34,097] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
      "[2022-10-07 09:04:34,113] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-demo-v1-res3/Eplus-env-sub_run10\n",
      "[2022-10-07 09:04:49,378] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus episode completed successfully. \n",
      "[2022-10-07 09:04:49,381] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
      "[2022-10-07 09:04:49,406] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/examples/Eplus-env-demo-v1-res3/Eplus-env-sub_run11\n",
      "Eval num_timesteps=140160, episode_reward=-22400.95 +/- 0.00\n",
      "Episode length: 35040.00 +/- 0.00\n",
      "New best mean reward!\n",
      "-----------------------------------------\n",
      "| eval/                     |           |\n",
      "|    comfort_penalty        | -1.83e+04 |\n",
      "|    comfort_violation(%)   | 34.3      |\n",
      "|    mean_ep_length         | 3.5e+04   |\n",
      "|    mean_power_consumption | 2.65e+08  |\n",
      "|    mean_rewards           | -22400.95 |\n",
      "|    power_penalty          | -2.65e+04 |\n",
      "|    std_rewards            | 0.0       |\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 3.5e+04   |\n",
      "|    ep_rew_mean            | -2.31e+04 |\n",
      "|    exploration_rate       | 0.05      |\n",
      "| time/                     |           |\n",
      "|    episodes               | 4         |\n",
      "|    fps                    | 825       |\n",
      "|    time_elapsed           | 169       |\n",
      "|    total_timesteps        | 140160    |\n",
      "| train/                    |           |\n",
      "|    learning_rate          | 0.0001    |\n",
      "|    loss                   | 9.05      |\n",
      "|    n_updates              | 22539     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.dqn.dqn.DQN at 0x7f8e66038ee0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(\n",
    "    total_timesteps=timesteps,\n",
    "    callback=callback,\n",
    "    log_interval=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now we save the current model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.save(env.simulator._env_working_dir_parent + '/' + name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "And as always, remember to close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-10-07 09:04:54,736] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus simulation closed successfully. \n"
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
