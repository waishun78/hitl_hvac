<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>7. Rewards &mdash; sinergym  documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../_static/doc_theme.css?v=816ccb90" />

  
    <link rel="shortcut icon" href="../_static/logo-sidebar.png"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=5929fcd5"></script>
        <script src="../_static/doctools.js?v=9a2dae69"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="8. Controllers" href="controllers.html" />
    <link rel="prev" title="6. Environments Configuration and Registration" href="environments_registration.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #a5beba" >

          
          
          <a href="../index.html" class="icon icon-home">
            sinergym
              <img src="../_static/logo-sidebar.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Start Here</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">1. Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="usage-example.html">2. Usage example</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">sinergym</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="buildings.html">3. Buildings</a></li>
<li class="toctree-l1"><a class="reference internal" href="weathers.html">4. Weathers</a></li>
<li class="toctree-l1"><a class="reference internal" href="environments.html">5. Environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="environments_registration.html">6. Environments Configuration and Registration</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">7. Rewards</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#reward-terms">7.1. Reward terms</a></li>
<li class="toctree-l2"><a class="reference internal" href="#custom-rewards">7.2. Custom Rewards</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="controllers.html">8. Controllers</a></li>
<li class="toctree-l1"><a class="reference internal" href="wrappers.html">9. Wrappers</a></li>
<li class="toctree-l1"><a class="reference internal" href="extra-configuration.html">10. Extra Configuration in Sinergym simulations</a></li>
<li class="toctree-l1"><a class="reference internal" href="output.html">11. Output format</a></li>
<li class="toctree-l1"><a class="reference internal" href="deep-reinforcement-learning.html">12. Deep Reinforcement Learning Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="gcloudAPI.html">13. Sinergym with Google Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="github-actions.html">14. Github Actions</a></li>
<li class="toctree-l1"><a class="reference internal" href="tests.html">15. Tests</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="notebooks/basic_example.html">16. Basic example</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/getting_env_information.html">17. Getting information about Sinergym environments</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/change_environment.html">18. Changing an environment registered in Sinergym</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/default_building_control.html">19. Default building control setting up an empty action interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/wrappers_examples.html">20. Wrappers example</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/personalize_loggerwrapper.html">21. Logger Wrapper personalization/configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/rule_controller_example.html">22. Rule Controller example</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/drl.html">23. DRL usage example</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="API-reference.html">API reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #a5beba" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">sinergym</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active"><span class="section-number">7. </span>Rewards</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/pages/rewards.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="rewards">
<h1><span class="section-number">7. </span>Rewards<a class="headerlink" href="#rewards" title="Link to this heading"></a></h1>
<p>Defining a reward function is crucial in reinforcement learning. Consequently, <em>Sinergym</em> offers
the option to use pre-implemented reward functions or define custom ones (see section below).</p>
<p><em>Sinergym</em>’s predefined reward functions are developed as <strong>multi-objective</strong>, incorporating both
<em>energy consumption</em> and <em>thermal discomfort</em>, which are normalized and combined with different weights.
These rewards are <strong>always negative</strong>, indicating that optimal behavior results in a cumulative reward of 0.
There are separate temperature comfort ranges defined for summer and winter periods. The weights assigned
to each term in the reward function allow for adjusting the importance of each aspect during environment evaluation.</p>
<p>The main idea behind the reward system in <em>Sinergym</em> is captured by the equation:</p>
<div class="math notranslate nohighlight">
\[r_t = - \omega \ \lambda_P \ P_t - (1 - \omega) \ \lambda_T \ (|T_t - T_{up}| + |T_t - T_{low}|)\]</div>
<p>Where: <br />
<span class="math notranslate nohighlight">\(P_t\)</span> represents power consumption, <br />
<span class="math notranslate nohighlight">\(T_t\)</span> is the current indoor temperature, <br />
<span class="math notranslate nohighlight">\(T_{up}\)</span> and <span class="math notranslate nohighlight">\(T_{low}\)</span> are the upper and lower comfort range limits, respectively, <br />
<span class="math notranslate nohighlight">\(\omega\)</span> is the weight assigned to power consumption, and consequently, <span class="math notranslate nohighlight">\(1 - \omega\)</span> represents the comfort weight, <br />
<span class="math notranslate nohighlight">\(\lambda_P\)</span> and <span class="math notranslate nohighlight">\(\lambda_T\)</span> are scaling constants for consumption and comfort penalties, respectively.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The constants <span class="math notranslate nohighlight">\(\lambda_P\)</span> and <span class="math notranslate nohighlight">\(\lambda_T\)</span> are set to establish a proportional
relationship between energy and comfort penalties, calibrating their magnitudes. If you’re working with different buildings,
it’s important to adjust these constants to ensure a similar magnitude of the reward components.</p>
</div>
<p>Different types of reward functions are developed based on specific details:</p>
<ul>
<li><dl class="simple">
<dt><code class="docutils literal notranslate"><span class="pre">LinearReward</span></code> implements a <strong>linear reward</strong> function where discomfort is calculated as the</dt><dd><p>absolute difference between the current temperature and the comfort range.</p>
</dd>
</dl>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">ExpReward</span></code> is similar to linear reward, but discomfort is calculated using the <strong>exponential
difference</strong> between current temperature and comfort ranges, resulting in a higher penalty for
greater deviations from target temperatures.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">HourlyLinearReward</span></code> adjusts the weight given to discomfort based on the <strong>hour of the day</strong>,
focusing more on energy consumption outside working hours.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">NormalizedLinearReward</span></code> normalizes the reward components based on the maximum energy penalty
and comfort penalty, allowing for adaptability during the simulation. IN this reward is not required
the <span class="math notranslate nohighlight">\(\lambda_P\)</span> and <span class="math notranslate nohighlight">\(\lambda_T\)</span> constants to calibrate both magnitudes.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This reward function is not very precise at the beginning of the simulation, be careful with that.</p>
</div>
</li>
</ul>
<p>These reward functions have parameters in their constructors whose values may vary depending on the building used
or other characteristics. By default, all environments use <code class="docutils literal notranslate"><span class="pre">LinearReward</span></code> with default parameters for each building.
If you want to change this, see an example in <a class="reference internal" href="notebooks/change_environment.html#Adding-a-new-reward"><span class="std std-ref">Adding a new reward</span></a>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When specifying a different reward with <cite>gym.make</cite> than the
default environment ID, it is very important to set the <cite>reward_kwargs</cite>
that are required and therefore do not have a default value.</p>
</div>
<section id="reward-terms">
<h2><span class="section-number">7.1. </span>Reward terms<a class="headerlink" href="#reward-terms" title="Link to this heading"></a></h2>
<p>By default, reward functions will return the <strong>reward scalar value</strong> and the <strong>terms</strong> used in their calculation.
The values of these terms depend on the specific reward function used. They will be automatically
added to the info dictionary in the environment. Typically, the structure will be the same as depicted
in the diagram below:</p>
<a class="reference internal image-reference" href="../_images/reward_terms.png"><img alt="Reward terms" class="align-center" src="../_images/reward_terms.png" style="width: 1197.0px; height: 572.5999999999999px;" /></a>
</section>
<section id="custom-rewards">
<h2><span class="section-number">7.2. </span>Custom Rewards<a class="headerlink" href="#custom-rewards" title="Link to this heading"></a></h2>
<p>It’s also straightforward to define custom reward functions. For example, a reward signal that always returns -1
can be implemented as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sinergym.utils.rewards</span> <span class="kn">import</span> <span class="n">BaseReward</span>

<span class="k">class</span> <span class="nc">CustomReward</span><span class="p">(</span><span class="n">BaseReward</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Naive reward function.&quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CustomReward</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs_dict</span><span class="p">):</span>
        <span class="k">return</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="p">{}</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">&#39;Eplus-discrete-stochastic-mixed-v1&#39;</span><span class="p">,</span> <span class="n">reward</span><span class="o">=</span><span class="n">CustomReward</span><span class="p">)</span>
</pre></div>
</div>
<p>For advanced reward functions, we suggest inheriting from our main class, <code class="docutils literal notranslate"><span class="pre">LinearReward</span></code>, and overriding relevant methods.
Our reward functions streamline observation processing to derive consumption and comfort violation data, from which absolute
penalty values are calculated. Subsequently, weighted reward terms are calculated from penalties and summed.</p>
<a class="reference internal image-reference" href="../_images/reward_structure.png"><img alt="Reward steps structure" class="align-center" src="../_images/reward_structure.png" style="width: 925.4px; height: 492.79999999999995px;" /></a>
<p>By modularizing each of these steps, you can swiftly and conveniently modify specific aspects of the reward to create a new one,
as demonstrated with our <em>exponential function reward version</em>, for example.</p>
<p><em>More reward functions will be included in the future, so stay tuned!</em></p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="environments_registration.html" class="btn btn-neutral float-left" title="6. Environments Configuration and Registration" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="controllers.html" class="btn btn-neutral float-right" title="8. Controllers" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, J. Jiménez, J. Gómez, M. Molina, A. Manjavacas, A. Campoy.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
    <span class="rst-current-version" data-toggle="rst-current-version">
        <span class="fa fa-book"> Other Versions</span>
        v: v3.2.10
        <span class="fa fa-caret-down"></span>
    </span>
    <div class="rst-other-versions">
        <dl>
            <dt>Tags</dt>
            <dd><a href="../../v1.4.0/pages/rewards.html">v1.4.0</a></dd>
            <dd><a href="../../v1.6.0/pages/rewards.html">v1.6.0</a></dd>
            <dd><a href="../../v1.7.0/pages/rewards.html">v1.7.0</a></dd>
            <dd><a href="../../v2.0.0/pages/rewards.html">v2.0.0</a></dd>
            <dd><a href="../../v2.1.0/pages/rewards.html">v2.1.0</a></dd>
            <dd><a href="../../v2.2.0/pages/rewards.html">v2.2.0</a></dd>
            <dd><a href="../../v2.3.0/pages/rewards.html">v2.3.0</a></dd>
            <dd><a href="../../v2.5.0/pages/rewards.html">v2.5.0</a></dd>
            <dd><a href="../../v3.1.0/pages/rewards.html">v3.1.0</a></dd>
            <dd><a href="../../v3.2.0/pages/rewards.html">v3.2.0</a></dd>
            <dd><a href="rewards.html">v3.2.10</a></dd>
            <dd><a href="../../v3.3.0/pages/rewards.html">v3.3.0</a></dd>
        </dl>
        <dl>
            <dt>Branches</dt>
            <dd><a href="../../main/pages/rewards.html">main</a></dd>
        </dl>
    </div>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>  

<style>
    /* Sidebar header (and topbar for mobile) */
    .wy-side-nav-search,
    .wy-nav-top {
        background: #a5beba;
    }

    /* Sidebar */
    .wy-nav-side {
        background: #2b3435;
    }
</style>


</body>
</html>