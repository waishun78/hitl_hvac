{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Logger Wrapper personalization/configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We will see on this notebook how to personalize the logger wrapper defined by sinergym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import sinergym\n",
    "from sinergym.utils.wrappers import (LoggerWrapper, MultiObsWrapper,\n",
    "                                     NormalizeObservation)\n",
    "from sinergym.utils.constants import RANGES_5ZONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 Inherit and modify the CSVloger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "First we need to change the CSV logger to modify the values writen into the file on the funtion create_row_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from sinergym.utils.logger import CSVLogger\n",
    "from typing import Any, Dict, Optional, Sequence, Tuple, Union, List\n",
    "\n",
    "class CustomCSVLogger(CSVLogger):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            monitor_header: str,\n",
    "            progress_header: str,\n",
    "            log_progress_file: str,\n",
    "            log_file: Optional[str] = None,\n",
    "            flag: bool = True):\n",
    "        super(CustomCSVLogger, self).__init__(monitor_header,progress_header,log_progress_file,log_file,flag)\n",
    "        self.last_10_steps_reward = [0]*10\n",
    "\n",
    "    def _create_row_content(\n",
    "            self,\n",
    "            obs: List[Any],\n",
    "            action: Union[int, np.ndarray, List[Any]],\n",
    "            reward: Optional[float],\n",
    "            done: bool,\n",
    "            info: Optional[Dict[str, Any]]) -> List:\n",
    "            \n",
    "        if reward is not None:\n",
    "            self.last_10_steps_reward.pop(0)\n",
    "            self.last_10_steps_reward.append(reward)\n",
    "\n",
    "        if info is None:  # In a reset\n",
    "            return [0] + list(obs) + list(action) + \\\n",
    "                [0, reward, np.mean(self.last_10_steps_reward), None, None, None, done]\n",
    "        else:\n",
    "            return [\n",
    "                info['timestep']] + list(obs) + list(action) + [\n",
    "                info['time_elapsed'],\n",
    "                reward,\n",
    "                np.mean(self.last_10_steps_reward),\n",
    "                info['total_power_no_units'],\n",
    "                info['comfort_penalty'],\n",
    "                info['abs_comfort'],\n",
    "                done]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 2 Intanciate the LoggerWrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "now we need to instantiate the loggerwrapper and specify the new headers of our file and the csvlogger class we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-06-21 09:33:58,455] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Updating idf ExternalInterface object if it is not present...\n",
      "[2022-06-21 09:33:58,456] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Updating idf Site:Location and SizingPeriod:DesignDay(s) to weather and ddy file...\n",
      "[2022-06-21 09:33:58,458] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Updating idf OutPut:Variable and variables XML tree model for BVCTB connection.\n",
      "[2022-06-21 09:33:58,460] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Setting up extra configuration in building model if exists...\n"
     ]
    }
   ],
   "source": [
    "env=gym.make('Eplus-demo-v1')\n",
    "env=LoggerWrapper(env,logger_class=CustomCSVLogger,monitor_header = ['timestep'] + env.variables['observation'] +\n",
    "                env.variables['action'] + ['time (seconds)', 'reward', '10-mean-reward',\n",
    "                'power_penalty', 'comfort_penalty', 'done'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can see in Sinergym output folder that you will have available `progress.csv` file and `monitor.csv` files in each episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-06-21 09:34:00,784] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
      "[2022-06-21 09:34:00,794] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /workspaces/sinergym/Eplus-env-demo-v1-res2/Eplus-env-sub_run1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward:  -0.3808358083250144 {'timestep': 1, 'time_elapsed': 900, 'year': 1991, 'month': 1, 'day': 1, 'hour': 0, 'total_power': 7616.716166500288, 'total_power_no_units': -0.7616716166500288, 'comfort_penalty': -0.0, 'abs_comfort': 0.0, 'temperatures': [20.99998783039325], 'out_temperature': 1.8, 'action_': [21, 21]}\n",
      "Reward:  -1817.7037351644783 {'timestep': 2976, 'time_elapsed': 2678400, 'year': 1991, 'month': 2, 'day': 1, 'hour': 0, 'total_power': 8278.265126379221, 'total_power_no_units': -0.8278265126379222, 'comfort_penalty': -0.0, 'abs_comfort': 0.0, 'temperatures': [20.09635860317218], 'out_temperature': -7.0, 'action_': [20, 25]}\n",
      "Reward:  -3569.893869126496 {'timestep': 5664, 'time_elapsed': 5097600, 'year': 1991, 'month': 3, 'day': 1, 'hour': 0, 'total_power': 833.2920927358493, 'total_power_no_units': -0.08332920927358493, 'comfort_penalty': -0.43408478076705137, 'abs_comfort': 0.43408478076705137, 'temperatures': [19.56591521923295], 'out_temperature': 8.1, 'action_': [16, 29]}\n",
      "Reward:  -4726.825668121225 {'timestep': 8640, 'time_elapsed': 7776000, 'year': 1991, 'month': 4, 'day': 1, 'hour': 0, 'total_power': 186.5934720667916, 'total_power_no_units': -0.018659347206679163, 'comfort_penalty': -0.435109315811939, 'abs_comfort': 0.435109315811939, 'temperatures': [19.56489068418806], 'out_temperature': 7.7, 'action_': [16, 29]}\n",
      "Reward:  -5537.597449713271 {'timestep': 11520, 'time_elapsed': 10368000, 'year': 1991, 'month': 5, 'day': 1, 'hour': 0, 'total_power': 186.5934720667916, 'total_power_no_units': -0.018659347206679163, 'comfort_penalty': -0.0, 'abs_comfort': 0.0, 'temperatures': [20.49458320791672], 'out_temperature': 13.0, 'action_': [16, 29]}\n",
      "Reward:  -6292.769417325523 {'timestep': 14496, 'time_elapsed': 13046400, 'year': 1991, 'month': 6, 'day': 1, 'hour': 0, 'total_power': 1081.566582699994, 'total_power_no_units': -0.1081566582699994, 'comfort_penalty': -1.0006063738688589, 'abs_comfort': 1.0006063738688589, 'temperatures': [21.99939362613114], 'out_temperature': 18.4, 'action_': [22, 23]}\n",
      "Reward:  -9282.920861126457 {'timestep': 17376, 'time_elapsed': 15638400, 'year': 1991, 'month': 7, 'day': 1, 'hour': 0, 'total_power': 215.8190761704195, 'total_power_no_units': -0.02158190761704195, 'comfort_penalty': -2.219568577307669, 'abs_comfort': 2.219568577307669, 'temperatures': [20.78043142269233], 'out_temperature': 17.7, 'action_': [19, 26]}\n",
      "Reward:  -12634.156075131721 {'timestep': 20352, 'time_elapsed': 18316800, 'year': 1991, 'month': 8, 'day': 1, 'hour': 0, 'total_power': 4228.056578307433, 'total_power_no_units': -0.42280565783074325, 'comfort_penalty': -3.7050000356997295, 'abs_comfort': 3.7050000356997295, 'temperatures': [19.29499996430027], 'out_temperature': 20.6, 'action_': [19, 26]}\n",
      "Reward:  -15998.997030178922 {'timestep': 23328, 'time_elapsed': 20995200, 'year': 1991, 'month': 9, 'day': 1, 'hour': 0, 'total_power': 367.8874627648617, 'total_power_no_units': -0.03678874627648617, 'comfort_penalty': -2.6311272146660514, 'abs_comfort': 2.6311272146660514, 'temperatures': [20.36887278533395], 'out_temperature': 18.8, 'action_': [20, 25]}\n",
      "Reward:  -18840.99755962802 {'timestep': 26208, 'time_elapsed': 23587200, 'year': 1991, 'month': 10, 'day': 1, 'hour': 0, 'total_power': 186.5934720667916, 'total_power_no_units': -0.018659347206679163, 'comfort_penalty': -0.0, 'abs_comfort': 0.0, 'temperatures': [20.89715955527449], 'out_temperature': 13.3, 'action_': [20, 25]}\n",
      "Reward:  -19780.136585783544 {'timestep': 29184, 'time_elapsed': 26265600, 'year': 1991, 'month': 11, 'day': 1, 'hour': 0, 'total_power': 1676.829498258497, 'total_power_no_units': -0.16768294982584972, 'comfort_penalty': -0.0, 'abs_comfort': 0.0, 'temperatures': [21.00051072214852], 'out_temperature': 13.0, 'action_': [21, 21]}\n",
      "Reward:  -20847.657706575505 {'timestep': 32064, 'time_elapsed': 28857600, 'year': 1991, 'month': 12, 'day': 1, 'hour': 0, 'total_power': 1300.083757928305, 'total_power_no_units': -0.1300083757928305, 'comfort_penalty': -0.8838907434947707, 'abs_comfort': 0.8838907434947707, 'temperatures': [19.11610925650523], 'out_temperature': 5.1, 'action_': [19, 26]}\n",
      "Reward:  -22626.148434896502 {'timestep': 35040, 'time_elapsed': 31536000, 'year': 1992, 'month': 1, 'day': 1, 'hour': 0, 'total_power': 8146.94600014605, 'total_power_no_units': -0.814694600014605, 'comfort_penalty': -2.5231669758907707, 'abs_comfort': 2.5231669758907707, 'temperatures': [17.47683302410923], 'out_temperature': -12.0, 'action_': [16, 29]}\n",
      "Episode  0 Mean reward:  -0.6457234142378936 Cumulative reward:  -22626.148434896502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-06-21 09:34:15,548] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus simulation closed successfully. \n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    obs = env.reset()\n",
    "    rewards = []\n",
    "    done = False\n",
    "    current_month = 0\n",
    "    while not done:\n",
    "        a = env.action_space.sample()\n",
    "        obs, reward, done, info = env.step(a)\n",
    "        rewards.append(reward)\n",
    "        if info['month'] != current_month:  # display results every month\n",
    "            current_month = info['month']\n",
    "            print('Reward: ', sum(rewards), info)\n",
    "    print('Episode ', i, 'Mean reward: ', np.mean(\n",
    "        rewards), 'Cumulative reward: ', sum(rewards))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
